{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppm/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n",
      "/Users/ppm/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import datetime as dt\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:51291</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>6.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:51291' processes=6 cores=6>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(threads_per_worker=1, n_workers=6, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = pd.read_csv('companylist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalisttech = datalist.loc[datalist['Sector'] == 'Technology']\n",
    "datalisttechbillion = datalisttech.loc[datalisttech['MarketCap'].str.contains(\"B\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist = datalisttechbillion['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  217 of 217 completed\n",
      "\n",
      "1 Failed download:\n",
      "- API: 2m data not available for startTime=1593178200 and endTime=1599857541. The requested range must be within the last 60 days.\n"
     ]
    }
   ],
   "source": [
    "pandas_data = yf.download(tickers = tickerlist, period = '60d', interval = '2m', group_by='ticker', prepost=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for stock in tickerlist:\n",
    "#    pandas_data[stock].to_csv('stockdata/'+stock+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tryit = pandas_data['AAPL'].dropna()\n",
    "#tryit2 = pandas_data['GOOG'].dropna()\n",
    "#tryit2.columns = ['Open2', 'High2', 'low2', 'close2', 'Adjclose2', 'Volume2']\n",
    "#tryit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starttime1 = dt.datetime.now()\n",
    "#y = tryit.merge(tryit2, how='inner', left_index=True, right_index=True)\n",
    "#endtime1 = dt.datetime.now()\n",
    "#finaltime1 = endtime1-starttime1\n",
    "\n",
    "#starttime = dt.datetime.now()\n",
    "#s = coint(y['Open'], y['Open2'], autolag='aic')\n",
    "#endtime = dt.datetime.now()\n",
    "#finaltime = endtime-starttime\n",
    "#overalltime = endtime-starttime1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_coint_test(stock1, stock2):\n",
    "        pvaluetable = []\n",
    "        try:    \n",
    "            s1 = pd.read_csv('stockdata/'+stock1+'.csv').dropna()\n",
    "            s2 = pd.read_csv('stockdata/'+stock2+'.csv', header=0, names = ['Datetime', 'Open2', 'High2', 'low2', 'close2', \n",
    "                                                             'Adjclose2', 'Volume2']).dropna()\n",
    "            both_stocks = s1.merge(s2, on = 'Datetime')\n",
    "            if len(both_stocks['Open'].to_list()) <= 50:\n",
    "                pvaluetable.append([stock1, stock2, 1.0, -3])\n",
    "            else:\n",
    "                score, pvalue, _ = coint(both_stocks['Open'], both_stocks['Open2'], autolag='aic')\n",
    "                if pvalue <= 0.01:\n",
    "                    pvaluetable.append([stock1, stock2, pvalue, 1])\n",
    "                else:\n",
    "                    pvaluetable.append([stock1, stock2, pvalue, 0])\n",
    "            del s1\n",
    "            del s2\n",
    "            del both_stocks\n",
    "        except:\n",
    "            pvaluetable.append(stock1, stock2, 1.0, -1)\n",
    "        return pvaluetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_coint_test_memory(stock1, stock2):\n",
    "        pvaluetable = []\n",
    "        try:    \n",
    "            s1 = pandas_data[stock1].dropna()\n",
    "            s2 = pandas_data[stock2].dropna()\n",
    "            s2.columns = ['Open2', 'High2', 'low2', 'close2', \n",
    "                                                             'Adjclose2', 'Volume2']\n",
    "            both_stocks = s1.merge(s2, how='inner', left_index=True, right_index=True)\n",
    "            if len(both_stocks['Open'].to_list()) <= 50:\n",
    "                pvaluetable.append([stock1, stock2, 1.0, -3])\n",
    "            else:\n",
    "                score, pvalue, _ = coint(both_stocks['Open'], both_stocks['Open2'], autolag='aic')\n",
    "                if pvalue <= 0.01:\n",
    "                    pvaluetable.append([stock1, stock2, pvalue, 1])\n",
    "                else:\n",
    "                    pvaluetable.append([stock1, stock2, pvalue, 0])\n",
    "            del s1\n",
    "            del s2\n",
    "            del both_stocks\n",
    "        except:\n",
    "            pvaluetable.append(stock1, stock2, 1.0, -1)\n",
    "        return pvaluetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_large_test(tickers, start, rotations):\n",
    "    results = []\n",
    "    newlist = tickerlist\n",
    "    for count in np.arange(0, start):\n",
    "        newlist = listshift(newlist)\n",
    "    for count in np.arange(0, rotations):\n",
    "        newlist = listshift(newlist)\n",
    "        for stock_1, stock_2 in zip(tickerlist, newlist):\n",
    "            result = single_coint_test_memory(stock_1, stock_2)\n",
    "            results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listshift(ticker_list):\n",
    "    newlist = [ticker_list[-1]] + ticker_list[:-1]\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_coint(tickers, cores, rotations):\n",
    "    dask_coint = dask.delayed(dask_large_test)\n",
    "    dask_tasks_list = []\n",
    "    for count in np.arange(0, cores):\n",
    "        divisor = 1/cores\n",
    "        start = round(divisor*count*rotations)\n",
    "        newrotations = round(rotations/cores)\n",
    "        task = dask_coint(tickers, start, newrotations)\n",
    "        dask_tasks_list.append(task)\n",
    "    dask_persist_list = dask.persist(*dask_tasks_list)\n",
    "    computations = dask.compute(dask_persist_list)\n",
    "    return computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_dask_coint(tickers, rotations):\n",
    "    results = []\n",
    "    newlist = tickerlist\n",
    "    n = 0\n",
    "    for count in np.arange(0, rotations):\n",
    "        newlist = listshift(newlist)\n",
    "        n = n+1\n",
    "        print(n)\n",
    "        for stock_1, stock_2 in zip(tickerlist, newlist):\n",
    "            result = single_coint_test_memory(stock_1, stock_2)\n",
    "            results.append(result)\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tasktime():\n",
    "    starttime = dt.datetime.now()\n",
    "    taskfile = dask_coint(tickerlist, 6, 12)\n",
    "    endtime = dt.datetime.now()\n",
    "    time_elapsed = (endtime-starttime)\n",
    "    return taskfile, time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, timer = tasktime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=475, microseconds=654797)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow = pd.DataFrame(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 370.5 seconds - 12 rotations 4 cores\n",
    "# 459.6 seconds - 12 rotations non_dask_coint\n",
    "# 475 seconds - 12 rotations 6 cores ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
